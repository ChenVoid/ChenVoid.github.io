<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="">
  <meta name="keywords" content="3D Talking Face, Audio-driven, Diffusion, Knowledge Distillation, DiffusionTalker">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>DiffusionTalker</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <!-- <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script> -->
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<!-- <nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://hypernerf.github.io">
            HyperNeRF
          </a>
          <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a>
        </div>
      </div>
    </div>

  </div>
</nav> -->


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title"> DiffusionTalker: Personalization and Acceleration for Speech-Driven 3D Face Diffuser</h1>

          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://chenvoid.github.io/">Peng Chen*</a><sup>1,2</sup>,</span>
            <span class="author-block">
              <strong>Xiaobao Wei*</strong><sup>1,2</sup>,</span>
            <span class="author-block">
              <strong>Ming Lu</strong><sup>3</sup>,
            </span>
            <span class="author-block">
              <strong>Yitong Zhu</strong><sup>1,2</sup>,
            </span>
            <span class="author-block">
              <strong>Naiming Yao</strong><sup>1</sup>,
            </span>
            <span class="author-block">
              <strong>Xingyu Xiao</strong><sup>4</sup>,
            </span>
            <br>
            <span class="author-block">
              <strong>Hui Chen</strong><sup>1</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Institute of Software, Chinese Academy of Sciences,</span>
            <span class="author-block"><sup>2</sup>University of Chinese Academy of Sciences,</span>
            <span class="author-block"><sup>3</sup>Intel Labs China,</span>
            <span class="author-block"><sup>4</sup>Tsinghua University</span>

          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2311.16565"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>

              <!-- Video Link. -->
              <span class="link-block">
                <a href="#teaser"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/ChenVoid/DiffusionTalker"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video id="teaser" autoplay loop controls playsinline height="100%">
        <source src="./static/videos/diffusiontalker_arxiv.mp4"
                type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        <strong>DiffusionTalker</strong>: We reduce the steps of the diffusion model for faster inference by knowledge distillation. 
        Based on the model with fewer steps, given an audio sequence, we can find a matching identity embedding in the identity library to personalize the speaker's talking style.
      </h2>
    </div>
  </div>
</section>


<!-- <section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/steve.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/chair-tp.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-shiba">
          <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/shiba.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/fullbody.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-blueshirt">
          <video poster="" id="blueshirt" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/blueshirt.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-mask">
          <video poster="" id="mask" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/mask.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-coffee">
          <video poster="" id="coffee" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/coffee.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-toby">
          <video poster="" id="toby" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/toby2.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section> -->


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Speech-driven 3D facial animation has been an attractive task in both academia and industry. 
            Traditional methods mostly focus on learning a deterministic mapping from speech to animation. 
            Recent approaches start to consider the non-deterministic fact of speech-driven 3D face animation 
            and employ the diffusion model for the task. However, personalizing facial animation and accelerating 
            animation generation are still two major limitations of existing diffusion-based methods. 
            To address the above limitations, we propose DiffusionTalker, a diffusion-based method that utilizes contrastive 
            learning to personalize 3D facial animation and knowledge distillation to accelerate 3D animation generation. 
            Specifically, to enable personalization, we introduce a learnable talking identity to aggregate knowledge 
            in audio sequences. The proposed identity embeddings extract customized facial cues across different people 
            in a contrastive learning manner. During inference, users can obtain personalized facial animation based on 
            input audio, reflecting a specific talking style. With a trained diffusion model with hundreds of steps, 
            we distill it into a lightweight model with 8 steps for acceleration. Extensive experiments are conducted 
            to demonstrate that our method outperforms state-of-the-art methods. The code will be released. 
          </p>
        </div>
      </div>
    </div>
    <br>
    <br>
    
    <!-- Proposed Method. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Proposed Method</h2>
        <div class="content has-text-justified">
          <img src="./static/videos/diffusiontalker.png" alt="diffusiontalker">
          <p>
            <br>
            DiffusionTalker continuously removes Gaussian noise from noise-added facial animation during 
            the Denoise Process while updating the model's parameters to generate facial animation based on 
            input speech. In each step, the model consists of two parts: the personalization adapter, 
            which uses contrastive learning to match speech and identity features, and the forward procedure, 
            which adds noise to the facial parameters. Finally, all the information is fed into the talker decoder 
            to predict facial animation. DiffusionTalker employs a training approach which is knowledge distillation 
            and reduces the number of sampling steps by half.
          </p>
          <!-- <p>
            
          </p>
          <p>
            
          </p> -->
        </div>
      </div>
    </div>
    <!--/ Proposed Method. -->  
</section>




<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>
      @article{chen2023diffusiontalker,
        title={DiffusionTalker: Personalization and Acceleration for Speech-Driven 3D Face Diffuser},
        author={Chen, Peng and Wei, Xiaobao and Lu, Ming and Zhu, Yitong and Yao, Naiming and Xiao, Xingyu and Chen, Hui},
        journal={arXiv preprint arXiv:2311.16565},
        year={2023}
      }
</code></pre>
  </div>
</section>
 



<footer class="footer">
  <div class="container">
      <div class="content has-text-centered">
          <a class="icon-link" href="https://arxiv.org/abs/2311.16565">
              <i class="fas fa-file-pdf"></i>
          </a>
          <a class="icon-link" href="https://github.com/ChenVoid/DiffusionTalker" class="external-link" disabled>
              <i class="fab fa-github"></i>
          </a>
      </div>
      <div class="columns is-centered">
          <div class="column is-8">
              <div class="content">
                  <p style="text-align:center">
                    This website is licensed under a <a rel="license"
                    href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
                    Commons Attribution-ShareAlike 4.0 International License</a>.
                  </p>
                  <p style="text-align:center">
                    Website source code based on the <a
                    href="https://github.com/nerfies/nerfies.github.io">Nerfies</a> project page.
                  </p>

              </div>
          </div>
      </div>
  </div>
</footer>

</body>
</html>
