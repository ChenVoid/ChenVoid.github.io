﻿<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Peng Chen</title>
  
  <meta name="author" content="Peng Chen">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>🌐</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Peng Chen</name>
              </p>
              <p>I am a second-year master student at 
                <a href="http://www.is.cas.cn/">Institute of Software, Chinese Academy of Sciences</a>,
                 supervised by <a href="https://people.ucas.ac.cn/~huichen">Prof. Hui Chen</a> from ISCAS
                 and <a href="https://lu-m13.github.io/">Ming Lu</a> from Intel Labs China.
                 I received my B.S. in Computer Science from <a href="https://www.ustb.edu.cn/">University of Science and Technology, Beijing</a> in 2023 and obtained Beijing Distinguished Graduate Award and Beijing Outstanding Graduation Thesis.
              </p>
              <p>
                I serve as a reviewer for international conferences including ICLR and ISMAR.
              </p>
              <p>
                I am seeking a PhD opportunity closely aligned with my research interests.
              </p>
              <p>
                My research focuses on <b>3D Vision</b>, <b>AIGC</b>, and <b>VLM</b>, involving technologies like 3DGS, Diffusion, LLaVA, and their derivatives, with applications in digital humans, image generation, and image/video understanding.
              </p>              
              <p style="text-align:center">
                <a href="mailto:chenpeng.cp0225@gmail.com">Email</a> &nbsp/&nbsp
                <a href="https://github.com/ChenVoid">Github</a> &nbsp/&nbsp  
                <a href="https://scholar.google.com/citations?user=uKqB810AAAAJ&hl=zh-CN">Google Scholar</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="assets/imgs/avatar.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="assets/imgs/avatar.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="two" id="Mixed_image" style="display: inline;"> 
              </div>
                <img src='assets/imgs/Mixed.png' alt="Mixed" width="320" height="180">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://chenvoid.github.io/MGA/">
                <papertitle>[arXiv preprint, 2024]</papertitle>
                MixedGaussianAvatar: Realistically and Geometrically Accurate Head Avatar via Mixed 2D-3D Gaussians
              </a>
              <br>
              <strong>Peng Chen</strong>,
              Xiaobao Wei,
              Qingpo Wuwu,
              Xinyi Wang,
              Xingyu Xiao,
              Ming Lu
              <br>
              
              <!-- <a href="./I-MedSAM">Project</a>
              / -->
              <a href="https://chenvoid.github.io/MGA/">Paper</a>
              /
              <a href="https://chenvoid.github.io/MGA/">Project</a>
              /
              <a href="https://chenvoid.github.io/MGA/">Code</a>
              <p></p>
              <p>
                We use 2DGS to maintain the surface geometry and employ 3DGS for color correction in areas where the rendering quality of 2DGS is insufficient, reconstructing a realistically and geometrically accurate 3D head avatar.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="two" id="GazeGaussian_image" style="display: inline;"> 
              </div>
                <img src='assets/imgs/GazeGaussian.png' alt="GazeGaussian" width="320" height="180">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ucwxb.github.io/GazeGaussian/">
                <papertitle>[arXiv preprint, 2024]</papertitle>
                GazeGaussian: High-Fidelity Gaze Redirection with 3D Gaussian Splatting
              </a>
              <br>
              Xiaobao Wei,
              <strong>Peng Chen</strong>,
              Guangyu Li,
              Ming Lu,
              Hui Chen,
              Feng Tian
              <br>
              

              <a href="https://arxiv.org/pdf/2411.12981">Paper</a>
              /
              <a href="https://ucwxb.github.io/GazeGaussian/">Project</a>
              /
              <a href="https://ucwxb.github.io/GazeGaussian/">Code</a>
              <p></p>
              <p>
                We propose GazeGaussian, a high-fidelity gaze redirection method that uses a two-stream 3DGS model to represent the face and eye regions separately.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="two" id="VARP_image" style="display: inline;"> 
              </div>
                <img src='assets/imgs/VARP.png' alt="VARP" width="320" height="180">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://varp-agent.github.io/">
                <papertitle>[NeurIPS Workshop, 2024]</papertitle>
                Can VLMs Play Action Role-Playing Games? Take Black Myth Wukong as a Study Case
              </a>
              <br>
              <strong>Peng Chen*</strong>,
              Pi Bu*,
              Jun Song,
              Yuan Gao,
              Bo Zheng
              <br>
              
              <!-- <a href="./I-MedSAM">Project</a>
              / -->
              <a href="https://arxiv.org/pdf/2409.12889">Paper</a>
              /
              <a href="https://varp-agent.github.io/">Project</a>
              <!-- /
              <a href="https://github.com/ChenVoid/DiffusionTalker">Code</a> -->
              <p></p>
              <p>
                We propose a novel framework named the VARP agent, which directly takes game screenshots as input and generates keyboard and mouse operations to play the ARPG.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="two" id="DiffusionTalker_image" style="display: inline;"> 
              </div>
                <img src='assets/imgs/DiffusionTalker.png' alt="DiffusionTalker" width="320" height="180">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="./DiffusionTalker">
                <papertitle>[arXiv preprint, 2023]</papertitle>
                DiffusionTalker: Personalization and Acceleration for Speech-Driven 3D Face Diffuser
              </a>
              <br>
              <strong>Peng Chen*</strong>,
              Xiaobao Wei*,
              Ming Lu,
              Yitong Zhu,
              Naiming Yao,
              Xingyu Xiao,
              Hui Chen
              <br>
              <!-- <a href="./I-MedSAM">Project</a>
              / -->
              <a href="https://arxiv.org/abs/2311.16565">Paper</a>
              /
              <a href="https://chenvoid.github.io/DiffusionTalker/">Project</a>
              /
              <a href="https://github.com/ChenVoid/DiffusionTalker">Code</a>
              <p></p>
              <p>
                We propose DiffusionTalker, a diffusion-based method that utilizes contrastive learning to personalize 3D facial animation and knowledge distillation to accelerate 3D animation generation.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="two" id="BYOC_image" style="display: inline;"> 
              </div>
                <img src='assets/imgs/BYOC.png' alt="BYOC" width="320" height="180">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2402.13724">
                <papertitle>[IEEE VR, 2024]</papertitle>
                Bring Your Own Character: A Holistic Solution for Automatic Facial Animation Generation of Customized Characters
              </a>
              <!-- &nbsp;&nbsp;<span style="color: red; font-style: italic;">(CCF-A)</span> -->
              <br>
              Zechen Bai,
              <strong>Peng Chen</strong>,
              Xiaolan Peng,
              Lu Liu,
              Naiming Yao,
              Hui Chen,
              <!-- Mike Zheng Shou, -->
              Feng Tian
              <br>
              <!-- <a href="./I-MedSAM">Project</a>
              / -->
              <a href="https://arxiv.org/pdf/2402.13724">Paper</a>
              <!-- / -->
              <!-- <a href="https://chenvoid.github.io/">Project</a> -->
              /
              <a href="https://github.com/showlab/BYOC">Code</a>
              <p></p>
              <p>
                Given a target facial video as reference, bring your own character into our solution integrated with Unity3D, it automatically generates facial animation for the virtual character.
              </p>
            </td>
          </tr>


        </tbody></table>
        

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr>
              <td style="padding:20px;width:100%;vertical-align:middle;">
                <heading>Internships</heading>
              </td>
            </tr>
          </tbody>
        </table>
        
        <ul>
          <li>
            [04/2024 - 09/2024] <b>Alibaba, Taotian</b>
            <div style="margin-top:5px; margin-bottom:5px;">
              <!-- <img src="assets/imgs/taotian.png" alt="Alibaba Logo" style="height:30px;vertical-align:middle;margin-right:10px;"> -->
              Research Intern for MLLM and Agent, with research work including vision-based MLLM agents and fine-tuning as well as improvements to LLaVA.
            </div>
          </li>
          <li>
            [11/2023 - 04/2024] <b>AMD, Xilinx AI</b>
            <div style="margin-top:5px; margin-bottom:5px;">
              <!-- <img src="assets/imgs/AMD.png" alt="AMD Logo" style="height:30px;vertical-align:middle;margin-right:10px;"> -->
              Research Intern for Diffusion-based AIGC, especially focused on improving ControlNet and Stable Diffusion for image generation.
            </div>
          </li>
          <li>
            [07/2023 - 08/2023] <b>Baidu, ACG</b>
            <div style="margin-top:5px; margin-bottom:5px;">
              <!-- <img src="assets/imgs/baidu.png" alt="Baidu Logo" style="height:30px;vertical-align:middle;margin-right:10px;"> -->
              Research Intern for Wenxin LLM Evaluation.
            </div>
          </li>
        </ul>
        
        

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>News</heading>
          </td>
        </tr>
      </tbody></table>

      <ul>
        <li>
            [06/2023] Beijing Outstanding Graduation Design (Thesis), 2023.
        </li>
        <li>
            [06/2023] Beijing Distinguished Graduate Award, 2023.
        </li>
      </ul>

      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
        <tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle;">
              <heading>Miscellaneous</heading>
            </td>
          </tr>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle;">
              <details>
                <summary>Friends (click to expand, random order)</summary>
                <ul>
                  <li><a href="https://ucwxb.github.io/">Xiaobao Wei</a></li>
                </ul>
              </details>
            </td>
          </tr>
        </tbody>
      </table>
      

    <script type="text/javascript" id="mapmyvisitors" src="//mapmyvisitors.com/map.js?d=Ub-AFz6Brg0s71MHR-SCWHW5j3d5hIlEoETiFPMd-sk&cl=ffffff&w=a"></script>


					
    </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                Last updated: Nov. 2024
                <br>
                Web page design credit to <a href="https://jonbarron.info" style="font-size: 14px">Jon Barron</a>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
